# Comparing `tmp/cmd_queue-0.1.8-py3-none-any.whl.zip` & `tmp/cmd_queue-0.1.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 59902 bytes, number of entries: 22
--rw-r--r--  2.0 unx    14386 b- defN 23-Mar-05 05:14 cmd_queue/__init__.py
--rw-r--r--  2.0 unx     5235 b- defN 23-Mar-05 05:14 cmd_queue/__main__.py
--rw-r--r--  2.0 unx    10414 b- defN 23-Mar-05 05:14 cmd_queue/airflow_queue.py
--rw-r--r--  2.0 unx    10893 b- defN 23-Mar-05 05:14 cmd_queue/base_queue.py
--rw-r--r--  2.0 unx     4641 b- defN 23-Mar-05 05:14 cmd_queue/monitor_app.py
--rw-r--r--  2.0 unx    25403 b- defN 23-Mar-05 05:14 cmd_queue/serial_queue.py
--rw-r--r--  2.0 unx    20355 b- defN 23-Mar-05 05:14 cmd_queue/slurm_queue.py
--rw-r--r--  2.0 unx    41323 b- defN 23-Mar-05 05:14 cmd_queue/tmux_queue.py
--rw-r--r--  2.0 unx     1450 b- defN 23-Mar-05 05:14 cmd_queue/util/__init__.py
--rw-r--r--  2.0 unx     3373 b- defN 23-Mar-05 05:14 cmd_queue/util/richer.py
--rw-r--r--  2.0 unx     2264 b- defN 23-Mar-05 05:14 cmd_queue/util/texter.py
--rw-r--r--  2.0 unx     7032 b- defN 23-Mar-05 05:14 cmd_queue/util/textual_extensions.py
--rw-r--r--  2.0 unx     1663 b- defN 23-Mar-05 05:14 cmd_queue/util/util_algo.py
--rw-r--r--  2.0 unx    21540 b- defN 23-Mar-05 05:14 cmd_queue/util/util_networkx.py
--rw-r--r--  2.0 unx      719 b- defN 23-Mar-05 05:14 cmd_queue/util/util_tags.py
--rw-r--r--  2.0 unx     1078 b- defN 23-Mar-05 05:14 cmd_queue/util/util_tmux.py
--rw-rw-rw-  2.0 unx    11343 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/LICENSE
--rw-r--r--  2.0 unx    28531 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/WHEEL
--rw-r--r--  2.0 unx       54 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1822 b- defN 23-Mar-05 05:15 cmd_queue-0.1.8.dist-info/RECORD
-22 files, 213621 bytes uncompressed, 56968 bytes compressed:  73.3%
+Zip file size: 61535 bytes, number of entries: 22
+-rw-r--r--  2.0 unx    14386 b- defN 23-Apr-05 01:39 cmd_queue/__init__.py
+-rw-r--r--  2.0 unx     7162 b- defN 23-Apr-05 01:39 cmd_queue/__main__.py
+-rw-r--r--  2.0 unx    10414 b- defN 23-Apr-05 01:39 cmd_queue/airflow_queue.py
+-rw-r--r--  2.0 unx    10893 b- defN 23-Apr-05 01:39 cmd_queue/base_queue.py
+-rw-r--r--  2.0 unx     4641 b- defN 23-Apr-05 01:39 cmd_queue/monitor_app.py
+-rw-r--r--  2.0 unx    25974 b- defN 23-Apr-05 01:39 cmd_queue/serial_queue.py
+-rw-r--r--  2.0 unx    23359 b- defN 23-Apr-05 01:39 cmd_queue/slurm_queue.py
+-rw-r--r--  2.0 unx    41323 b- defN 23-Apr-05 01:39 cmd_queue/tmux_queue.py
+-rw-r--r--  2.0 unx     1450 b- defN 23-Apr-05 01:39 cmd_queue/util/__init__.py
+-rw-r--r--  2.0 unx     3373 b- defN 23-Apr-05 01:39 cmd_queue/util/richer.py
+-rw-r--r--  2.0 unx     2264 b- defN 23-Apr-05 01:39 cmd_queue/util/texter.py
+-rw-r--r--  2.0 unx     7032 b- defN 23-Apr-05 01:39 cmd_queue/util/textual_extensions.py
+-rw-r--r--  2.0 unx     1663 b- defN 23-Apr-05 01:39 cmd_queue/util/util_algo.py
+-rw-r--r--  2.0 unx    21540 b- defN 23-Apr-05 01:39 cmd_queue/util/util_networkx.py
+-rw-r--r--  2.0 unx      719 b- defN 23-Apr-05 01:39 cmd_queue/util/util_tags.py
+-rw-r--r--  2.0 unx     1078 b- defN 23-Apr-05 01:39 cmd_queue/util/util_tmux.py
+-rw-rw-rw-  2.0 unx    11343 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx    28531 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx       54 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1822 b- defN 23-Apr-05 01:40 cmd_queue-0.1.9.dist-info/RECORD
+22 files, 219123 bytes uncompressed, 58601 bytes compressed:  73.3%
```

## zipnote {}

```diff
@@ -42,26 +42,26 @@
 
 Filename: cmd_queue/util/util_tags.py
 Comment: 
 
 Filename: cmd_queue/util/util_tmux.py
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/LICENSE
+Filename: cmd_queue-0.1.9.dist-info/LICENSE
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/METADATA
+Filename: cmd_queue-0.1.9.dist-info/METADATA
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/WHEEL
+Filename: cmd_queue-0.1.9.dist-info/WHEEL
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/entry_points.txt
+Filename: cmd_queue-0.1.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/top_level.txt
+Filename: cmd_queue-0.1.9.dist-info/top_level.txt
 Comment: 
 
-Filename: cmd_queue-0.1.8.dist-info/RECORD
+Filename: cmd_queue-0.1.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cmd_queue/__init__.py

```diff
@@ -292,15 +292,15 @@
     >>>     airflow_queue = queue.change_backend('airflow')
     >>>     airflow_queue.run()
 """
 
 __mkinit__ = """
 mkinit -m cmd_queue
 """
-__version__ = '0.1.8'
+__version__ = '0.1.9'
 
 
 __submodules__ = {
     'base_queue': ['Queue'],
 }
 from cmd_queue import base_queue
```

## cmd_queue/__main__.py

```diff
@@ -11,27 +11,69 @@
     This is a modal CLI where "action" will specify the main behavior.
     Most behaviors are related to creating and submitting custom queues.
 
     The ``cleanup`` action is for helping to manage the tmux backend, maingly
     killing session names that start with "cmdq_".
 
     Example:
+
+        #################################
+        # Step 1:  Initialize a new queue
+        #################################
+
         cmd_queue new "my_cli_queue"
+
+        # Note if you are working in a virtualenv you need to specify a header
+        # to activate it if you are going to use the tmux or slurm backend
+        # (serial will work without this)
+
+        # e.g. for conda
+        cmd_queue new "my_cli_queue" --header="conda activate myenv"
+
+        # e.g. for pyenv
+        cmd_queue new "my_cli_queue" --header="pyenv shell 3.11.0 && source $PYENV_ROOT/versions/3.11.0/envs/pyenv3.11.0/bin/activate"
+
+        #################################
+        # Step 2:  Initialize a new queue
+        #################################
+
         cmd_queue submit "my_cli_queue" --  echo hello world
         cmd_queue submit "my_cli_queue" --  echo "hello world"
         cmd_queue submit "my_cli_queue" -- cowsay hellow world
         # Quotes are necessary if we are using bash constructs like &&
         cmd_queue submit "my_cli_queue" -- 'cowsay MOO && sleep 1'
         cmd_queue submit "my_cli_queue" -- 'cowsay MOOOO && sleep 2'
         cmd_queue submit "my_cli_queue" -- 'cowsay MOOOOOO && sleep 3'
         cmd_queue submit "my_cli_queue" -- 'cowsay MOOOOOOOO && sleep 4'
+
+        #################################
+        # Step 3:  Inspect your commands before you run
+        #################################
         cmd_queue show "my_cli_queue"
+
+        #################################
+        # Step 4:  Run your commands
+        #################################
+
+        # Run using the serial backend
         cmd_queue run "my_cli_queue" --backend=serial
+
+        # Run using the tmux backend
         cmd_queue run "my_cli_queue" --backend=tmux --workers=2
+
+        #################################
+        # Extra: other features
+        #################################
+
+        # List all the known queues you've created
         cmd_queue list
+
+        # Cleanup tmux sessions (useful when jobs are failing)
+        cmd_queue cleanup
+
     """
     action = scfg.Value(None, position=1, help='action', choices=[
         'cleanup', 'show', 'new', 'submit', 'run', 'list'], required=True)
 
     name = scfg.Value(None, position=2, help='name of the CLI queue')
 
     command = scfg.Value(None, position=3, nargs='*', help=ub.paragraph(
@@ -44,14 +86,17 @@
         then specify your full command.
         '''))
 
     workers = scfg.Value(1, help='number of concurrent queues for the tmux backend.')
 
     backend = scfg.Value('tmux', help='the execution backend to use', choices=['tmux', 'slurm', 'serial', 'airflow'])
 
+    # TODO: use a modal config to separate action behaviors
+    header = scfg.Value(None, help='a header command to execute in every session (e.g. activating a virtualenv). Only used when action is new')
+
     dpath = scfg.Value('auto', help=ub.paragraph(
         '''
         The path the CLI will use to store intermediate files. Defaults to $XDG_CACHE/.cache/cmd_queue/cli
         '''
     ))
 
     def normalize(config):
@@ -79,20 +124,24 @@
     if config['action'] == 'list':
         print(ub.urepr(list(cli_queue_dpath.glob('*.cmd_queue.json'))))
 
     elif config['action'] == 'new':
         # Start a new CLI queue
         data = []
         cli_queue_fpath.parent.ensuredir()
+
+        if config.header is not None:
+            data.append({'type': 'header', 'header': config.header})
+
         cli_queue_fpath.write_text(json.dumps(data))
 
     elif config['action'] == 'submit':
         # Run a new CLI queue
         data = json.loads(cli_queue_fpath.read_text())
-        data.append({'command': config['command']})
+        data.append({'type': 'command', 'command': config['command']})
         cli_queue_fpath.write_text(json.dumps(data))
 
     elif config['action'] == 'show':
         queue = build_queue(cli_queue_fpath, config)
         queue.rprint()
         queue.print_graph()
 
@@ -125,18 +174,24 @@
     import json
     queue = cmd_queue.Queue.create(size=max(1, config['workers']),
                                    backend=config['backend'],
                                    name=config['name'])
     # Run a new CLI queue
     data = json.loads(cli_queue_fpath.read_text())
     for row in data:
-        bash_command = row['command']
-        if isinstance(bash_command, list):
-            bash_command = ' '.join(bash_command)
-        queue.submit(bash_command, log=False)
+        if row['type'] == 'header':
+            bash_command = row['header']
+            if isinstance(bash_command, list):
+                bash_command = ' '.join(bash_command)
+            queue.add_header_command(bash_command)
+        elif row['type'] == 'command':
+            bash_command = row['command']
+            if isinstance(bash_command, list):
+                bash_command = ' '.join(bash_command)
+            queue.submit(bash_command, log=False)
     return queue
 
 if __name__ == '__main__':
     """
 
     CommandLine:
         python ~/code/cmd_queue/cmd_queue/__main__.py
```

## cmd_queue/serial_queue.py

```diff
@@ -35,30 +35,47 @@
 
 class BashJob(base_queue.Job):
     r"""
     A job meant to run inside of a larger bash file. Analog of SlurmJob
 
     Attributes:
         name (str): a name for this job
+
         pathid (str): a unique id based on the name and a hashed uuid
+
         command (str): the shell command to run
-        depends (List[BashJob] | None): the jobs that this job depends on
+
+        depends (List[BashJob] | None):
+            the jobs that this job depends on. This job will only run once all
+            the dependencies have succesfully run.
+
         bookkeeper (bool): flag indicating if this is a bookkeeping job or not
+
         info_dpath (PathLike | None): where information about this job will be stored
+
         log (bool):
             if True, output of the job will be tee-d and saved to a file, this
             can have interactions with normal stdout. Defaults to False.
+
         tags (List[str] | str | None):
             a list of strings that can be used to group jobs or filter the
             queue or other custom purposes.
+
         allow_indent (bool):
             In some cases indentation matters for the shell command.
             In that case ensure this is False at the cost of readability in the
             result script.
 
+    TODO:
+        - [ ] What is a good name for a a list of jobs that must fail
+              for this job to run. Our current depends in analogous to slurm's
+              afterok. What is a good variable name for afternotok? Do we
+              wrap the job with some sort of negation, so we depend on the
+              negation of the job?
+
     Example:
         >>> from cmd_queue.serial_queue import *  # NOQA
         >>> # Demo full boilerplate for a job with no dependencies
         >>> self = BashJob('echo hi', 'myjob')
         >>> self.print_commands(1, 1)
 
     Example:
@@ -68,14 +85,15 @@
         >>> conditionals = {'on_skip': ['echo "CUSTOM MESSAGE FOR WHEN WE SKIP A JOB"']}
         >>> self = BashJob('echo hi', name='job2', depends=[dep])
         >>> self.print_commands(1, 1, conditionals=conditionals)
     """
     def __init__(self, command, name=None, depends=None, gpus=None, cpus=None,
                  mem=None, bookkeeper=0, info_dpath=None, log=False, tags=None,
                  allow_indent=True, **kwargs):
+
         if depends is not None and not ub.iterable(depends):
             depends = [depends]
         self.name = name
         self.pathid = self.name + '_' + ub.hash_data(uuid.uuid4())[0:8]
         self.kwargs = kwargs  # unused kwargs
         self.command = command
         self.depends: list[base_queue.Job] = depends
@@ -131,14 +149,16 @@
         if with_status:
             if self.depends:
                 # Dont allow us to run if any dependencies have failed
                 conditions = []
                 for dep in self.depends:
                     if dep is not None:
                         conditions.append(f'[ -f {dep.pass_fpath} ]')
+                # TODO: if we add the ability to depend on jobs failing then
+                # add those conditions here.
                 if conditions:
                     had_conditions = True
                     condition = ' && '.join(conditions)
                     prefix_script.append(f'if {condition}; then')
 
         if with_status:
             script.append('# before_command:')
```

## cmd_queue/slurm_queue.py

```diff
@@ -53,30 +53,150 @@
         mem = reg.parse_expression(mem)
         mem = int(mem.to('megabytes').m)
     else:
         raise TypeError(type(mem))
     return mem
 
 
+# List of extra keys that can be specified as key/value pairs in sbatch args
+# These are acceptable kwargs for SlurmQueue.__init__ and SlurmQueue.submit
+__dev__ = r"""
+    # Script to build the modifier list
+
+    import ubelt as ub
+    import re
+    b = xdev.regex_builder.RegexBuilder.coerce('python')
+
+    blocklist = {'job_name', 'output', 'dependency', 'begin'}
+
+    keyval_pat = re.compile(r'--([\w-]+)=')
+    text = ub.cmd('sbatch --help')['out']
+    lines = ub.oset()
+    for key in keyval_pat.findall(text):
+        lines.append(key.replace('-', '_'))
+    print(ub.urepr(list(lines - blocklist)))
+
+
+    blocklist = {'mem', 'version', 'help', 'usage'}
+    flag_pat = re.compile(r'--([\w-]+) ')
+    lines = ub.oset()
+    for key in flag_pat.findall(text):
+        lines.append(key.replace('-', '_'))
+    print(ub.urepr(list(lines - blocklist)))
+"""
+
+SLURM_SBATCH_KVARGS = [
+    'array',
+    'account',
+    'bb',
+    'bbf',
+    # 'begin',
+    'comment',
+    'cpu_freq',
+    'cpus_per_task',
+    # 'dependency',
+    'deadline',
+    'delay_boot',
+    'chdir',
+    'error',
+    'export_file',
+    'gid',
+    'gres',
+    'gres_flags',
+    'input',
+    # 'job_name',
+    'licenses',
+    'clusters',
+    'distribution',
+    'mail_type',
+    'mail_user',
+    'mcs_label',
+    'ntasks',
+    'ntasks_per_node',
+    'nodes',
+    # 'output',
+    'partition',
+    'power',
+    'priority',
+    'profile',
+    'qos',
+    'core_spec',
+    'signal',
+    'switches',
+    'thread_spec',
+    'time',
+    'time_min',
+    'uid',
+    'wckey',
+    'cluster_constraint',
+    'constraint',
+    'nodefile',
+    'mem',
+    'mincpus',
+    'reservation',
+    'tmp',
+    'nodelist',
+    'exclude',
+    'mem_per_cpu',
+    'sockets_per_node',
+    'cores_per_socket',
+    'threads_per_core',
+    'extra_node_info',
+    'ntasks_per_core',
+    'ntasks_per_socket',
+    'hint',
+    'mem_bind',
+    'cpus_per_gpu',
+    'gpus',
+    'gpu_bind',
+    'gpu_freq',
+    'gpus_per_node',
+    'gpus_per_socket',
+    'gpus_per_task',
+    'mem_per_gpu',
+]
+
+SLURM_SBATCH_FLAGS = [
+    'get_user_env',
+    'hold',
+    'ignore_pbs',
+    'no_kill',
+    'container',
+    'no_requeue',
+    'overcommit',
+    'parsable',
+    'quiet',
+    'reboot',
+    'requeue',
+    'oversubscribe',
+    'spread_job',
+    'use_min_nodes',
+    'verbose',
+    'wait',
+    'contiguous',
+    'mem_per_cpu',
+]
+
+
 class SlurmJob(base_queue.Job):
     """
     Represents a slurm job that hasn't been submitted yet
 
     Example:
         >>> from cmd_queue.slurm_queue import *  # NOQA
         >>> self = SlurmJob('python -c print("hello world")', 'hi', cpus=5, gpus=1, mem='10GB')
         >>> command = self._build_sbatch_args()
         >>> print('command = {!r}'.format(command))
         >>> self = SlurmJob('python -c print("hello world")', 'hi', cpus=5, gpus=1, mem='10GB', depends=[self])
         >>> command = self._build_command()
         >>> print(command)
     """
     def __init__(self, command, name=None, output_fpath=None, depends=None,
-                 partition=None, cpus=None, gpus=None, mem=None, begin=None,
-                 shell=None, tags=None, **kwargs):
+                 cpus=None, gpus=None, mem=None, begin=None, shell=None,
+                 tags=None, **kwargs):
         super().__init__()
         if name is None:
             import uuid
             name = 'job-' + str(uuid.uuid4())
         if depends is not None and not ub.iterable(depends):
             depends = [depends]
         self.unused_kwargs = kwargs
@@ -86,14 +206,17 @@
         self.depends = depends
         self.cpus = cpus
         self.gpus = gpus
         self.mem = mem
         self.begin = begin
         self.shell = shell
         self.tags = util_tags.Tags.coerce(tags)
+        # Extra arguments for sbatch
+        self._sbatch_kvargs = ub.udict(kwargs) & SLURM_SBATCH_KVARGS
+        self._sbatch_flags = ub.udict(kwargs) & SLURM_SBATCH_FLAGS
         # if shell not in {None, 'bash'}:
         #     raise NotImplementedError(shell)
 
         self.jobid = None  # only set once this is run (maybe)
         # --partition=community --cpus-per-task=5 --mem=30602 --gres=gpu:1
 
     def __nice__(self):
@@ -125,14 +248,23 @@
                     raise TypeError(type(self.gpus))
                 return gres
             gres = _coerce_gres(self.gpus)
             sbatch_args.append(f'--gres="{gres}"')
         if self.output_fpath:
             sbatch_args.append(f'--output="{self.output_fpath}"')
 
+        for key, value in self._sbatch_kvargs.items():
+            key = key.replace('_', '-')
+            sbatch_args.append(f'--{key}="{value}"')
+
+        for key, flag in self._sbatch_flags.items():
+            if flag:
+                key = key.replace('_', '-')
+                sbatch_args.append(f'--{key}"')
+
         import shlex
         wrp_command = shlex.quote(self.command)
 
         if self.shell:
             wrp_command = shlex.quote(self.shell + ' -c ' + wrp_command)
 
         sbatch_args.append(f'--wrap {wrp_command}')
@@ -230,14 +362,16 @@
         self.queue_id = name + '-' + stamp + '-' + ub.hash_data(uuid.uuid4())[0:8]
         self.dpath = ub.Path.appdir('cmd_queue/slurm') / self.queue_id
         self.log_dpath = self.dpath / 'logs'
         self.fpath = self.dpath / (self.queue_id + '.sh')
         self.shell = shell
         self.header_commands = []
         self.all_depends = None
+        self._sbatch_kvargs = ub.udict(kwargs) & SLURM_SBATCH_KVARGS
+        self._sbatch_flags = ub.udict(kwargs) & SLURM_SBATCH_FLAGS
 
     def __nice__(self):
         return self.queue_id
 
     @classmethod
     def is_available(cls):
         """
@@ -285,15 +419,16 @@
             # Resolve any strings to job objects
             if not ub.iterable(depends):
                 depends = [depends]
             depends = [
                 self.named_jobs[dep] if isinstance(dep, str) else dep
                 for dep in depends]
 
-        job = SlurmJob(command, depends=depends, **kwargs)
+        _kwargs = self._sbatch_kvargs | kwargs
+        job = SlurmJob(command, depends=depends, **_kwargs)
         self.jobs.append(job)
         self.num_real_jobs += 1
         self.named_jobs[job.name] = job
         return job
 
     def add_header_command(self, command):
         self.header_commands.append(command)
@@ -420,15 +555,15 @@
 
     def read_state(self):
         # Not possible to get full info, but we probably could do better than
         # this
         return {}
 
     def print_commands(self, with_status=False, with_rich=None, colors=0,
-                       exclude_tags=None, style='auto'):
+                       exclude_tags=None, style='auto', **kw):
         """
         Print info about the commands, optionally with rich
 
         Example:
             >>> from cmd_queue.slurm_queue import *  # NOQA
             >>> self = SlurmQueue('test-slurm-queue')
             >>> self.submit('echo hi 1')
```

## Comparing `cmd_queue-0.1.8.dist-info/LICENSE` & `cmd_queue-0.1.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `cmd_queue-0.1.8.dist-info/METADATA` & `cmd_queue-0.1.9.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cmd-queue
-Version: 0.1.8
+Version: 0.1.9
 Summary: The cmd_queue module for a DAG of bash commands
 Home-page: https://gitlab.kitware.com/computer-vision/cmd_queue
 Author: Kitware Inc., Jon Crall
 Author-email: kitware@kitware.com, jon.crall@kitware.com
 License: Apache 2
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
```

## Comparing `cmd_queue-0.1.8.dist-info/RECORD` & `cmd_queue-0.1.9.dist-info/RECORD`

 * *Files 13% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-cmd_queue/__init__.py,sha256=MVbrOzvLAKuKMRIVVd5Z-6CEHE-4Uka7e5dWMorq7SY,14386
-cmd_queue/__main__.py,sha256=647tZjc8u7X7RgBhw7sE_vgImiVEPn1Wkxus-rlQbfI,5235
+cmd_queue/__init__.py,sha256=eFbSPjQtohGyAbpJ3wi-9tdlnA5Um-vPFA3EouR0vtM,14386
+cmd_queue/__main__.py,sha256=RjKVh1CP0BNS_xzWftHhGPAbvLciZotJNSuPbkR5f04,7162
 cmd_queue/airflow_queue.py,sha256=zJ86GckW5yXVcy9gCK7dmRlezs7H5ABpUWK7FeVtJSk,10414
 cmd_queue/base_queue.py,sha256=ZfuFIgsZGu8GCAPC3KPk8fq4kf_59GtKbpDJdrOSDHg,10893
 cmd_queue/monitor_app.py,sha256=m0cROUkBvTfpArjdZBfDvBMYnVJKBU_gDiW4HqENm0o,4641
-cmd_queue/serial_queue.py,sha256=l2EJb5EtsYrzkwqhsv3zlpGgxtzJaYf2u8saERNZLWw,25403
-cmd_queue/slurm_queue.py,sha256=lrpBxks8vZF7z0jXp430bUK5apjpA7YZ-V3hsMnmtSQ,20355
+cmd_queue/serial_queue.py,sha256=WnQ1i1-3upII2v5543Nf6j_QA57elhQJHqPKHJG4u_o,25974
+cmd_queue/slurm_queue.py,sha256=ZF09zP5wrSU04NHzVLbLtzi4KepK7DNLEIeVUdvyBhw,23359
 cmd_queue/tmux_queue.py,sha256=1_zV7fSzzecBv1sYO0OwsPwH6-2aFH6DzZ8nGsduDwg,41323
 cmd_queue/util/__init__.py,sha256=QzlId47F1lzuLyeIIJoPGZR3b9ljJl50sFEcJzYWrB8,1450
 cmd_queue/util/richer.py,sha256=OPXpoXYgdhv_49sskF9FMwj6KCSiNcBo1kNhbuj6hoU,3373
 cmd_queue/util/texter.py,sha256=I6Fcrk0Yp3QTgbxF8cn8vSZWIkkytGBk3ZD4c1diMM0,2264
 cmd_queue/util/textual_extensions.py,sha256=Rjign1BCxXGtbZ3qVFgGEzOr2E4CLFOftsUJ_1y4hGw,7032
 cmd_queue/util/util_algo.py,sha256=NSHXhNz0YThlks0Ku4Dki3NPCfw3SP-yI-Ul6wd3z30,1663
 cmd_queue/util/util_networkx.py,sha256=5CV8MCAokAnHneC-_Sg2sQ4MOxkj3KYpRNn_t8kyaP8,21540
 cmd_queue/util/util_tags.py,sha256=Hlxpel759AduUy3Wdq3fCe-XKjxqBUFCLOr3Mw2bzsw,719
 cmd_queue/util/util_tmux.py,sha256=vC4xeYZCV8uVAp363zD24ROyKqUAdCynIULNJ8UgLQE,1078
-cmd_queue-0.1.8.dist-info/LICENSE,sha256=o6jcFk_bwjiPUz6vHK0Ju7RwbFp9eXMwAS2BDnwER-4,11343
-cmd_queue-0.1.8.dist-info/METADATA,sha256=xt4UvD8NyOUbAfqkjCJg6x2lPiEmcWvcdx5tA53QE14,28531
-cmd_queue-0.1.8.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-cmd_queue-0.1.8.dist-info/entry_points.txt,sha256=HDxa1dTf0Dne-a-QeDu7cWZVYRyEtCvqaau0GCCMEyw,54
-cmd_queue-0.1.8.dist-info/top_level.txt,sha256=C2JVEsOZsjnMx3jIAWhIQGWAXjGs-hyBzzjkOIm7qW8,10
-cmd_queue-0.1.8.dist-info/RECORD,,
+cmd_queue-0.1.9.dist-info/LICENSE,sha256=o6jcFk_bwjiPUz6vHK0Ju7RwbFp9eXMwAS2BDnwER-4,11343
+cmd_queue-0.1.9.dist-info/METADATA,sha256=OV_OGIRvt4Gz9tp-CBnGr-eWvtPrkxR3FQE-ezereKY,28531
+cmd_queue-0.1.9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+cmd_queue-0.1.9.dist-info/entry_points.txt,sha256=HDxa1dTf0Dne-a-QeDu7cWZVYRyEtCvqaau0GCCMEyw,54
+cmd_queue-0.1.9.dist-info/top_level.txt,sha256=C2JVEsOZsjnMx3jIAWhIQGWAXjGs-hyBzzjkOIm7qW8,10
+cmd_queue-0.1.9.dist-info/RECORD,,
```

